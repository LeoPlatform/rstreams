[{"url":"https://rstreams.org/rstreams-guides/core-concepts/fundamentals/","title":"Fundamentals","description":"Fundamental concepts.","content":"Events Event ID TODO\nPipeline (Pipe) TODO\nPipeline Step TODO\nStream Pipeline Step or Bots/Queues. TODO\nCheckpoint Writing last read event ID back to queue. TODO\nEvent source timestamp Ancestors and derivatives and the value it provides TODO\nStarted timestamp (bot) TODO\nEnded timestamp (bot) TODO\nCorrelation ID (bot) TODO\nUnits (bot) TODO\nCheckpoint TODO\n"},{"url":"https://rstreams.org/why-rstreams/","title":"Why RStreams?","description":"What is RStreams and why should I use it?","content":"Why RStreams? Why not just AWS services? Less Friction AWS services rock. Each service started life to serve a specific purpose and then grew in size and scope, becoming useful to more and more use cases. Yet, each service was born and iterated from a starting foundation, giving each a sweet spot for where it excels and step outside this sweet spot and friction emerges.\n"},{"url":"https://rstreams.org/rstreams-botmon/getting-started/","title":"Getting Started","description":"","content":"Cras at dolor eget urna varius faucibus tempus in elit. Cras a dui imperdiet, tempus metus quis, pharetra turpis. Phasellus at massa sit amet ante semper fermentum sed eget lectus. Quisque id dictum magna turpis.\n Etiam vestibulum risus vel arcu elementum eleifend. Cras at dolor eget urna varius faucibus tempus in elit. Cras a dui imperdiet\n Etiam vestibulum risus vel arcu elementum eleifend. Cras at dolor eget urna varius faucibus tempus in elit. Cras a dui imperdiet, tempus metus quis, pharetra turpis. Phasellus at massa sit amet ante semper fermentum sed eget lectus. Quisque id dictum magna, et dapibus turpis.Etiam vestibulum risus vel arcu elementum eleifend. Cras at dolor eget urna varius faucibus tempus in elit. Cras a dui imperdiet, tempus metus quis, pharetra turpis. Phasellus at massa sit amet ante semper fermentum sed eget lectus. Quisque id dictum magna, et dapibus turpis.\n"},{"url":"https://rstreams.org/rstreams-bus/getting-started/","title":"Getting Started","description":"","content":"Coming soon\n"},{"url":"https://rstreams.org/rstreams-flow/getting-started/","title":"Getting Started","description":"","content":"Coming soon\n"},{"url":"https://rstreams.org/rstreams-node-sdk/getting-started/","title":"Getting Started","description":"","content":"\r ToC\r   Write a single object to the bus Write multiple objects to the bus Stream multiple objects to the bus fast    \r Are you setup to run the examples? Expand this section if you\u0026rsquo;re not sure  \rAll examples in the SDK documentation assume that when these apps run, the RStreams SDK can discover the configuration it needs. The config it needs is the AWS resource IDs of the RStreams Bus instance deployed in your AWS account. Things like the ID of the kinesis stream used by the bus and so on.\nOf course, in a production environment the SDK will get the config in an intelligent and safe manner, say from AWS Secrets Manager. See the RStreams Flow Configuring RStreams doc.\nHere\u0026rsquo;s the typescript type of the config.\nGet the config You will first need to get this config. By default, the RStreams Bus puts a secret in secrets manager that is the JSON config blob. The secret will be named rstreams-\u0026lt;bus name\u0026gt;. Go get the JSON config from this secret.\nSave the config As a file Create a file named rstreams.config.json and put it in the same directory you are running your app in or in any parent director and the SDK will just find it and use it.\nAs an environment variable Create an environment variable named RSTREAMS_CONFIG whose value is the config JSON blob.\nAs an argument to the SDK itself Create a variable in the code that is the config and then pass it into the SDK\u0026rsquo;s constructor.\n1 2const RSTREAMS_BUS_CONFIG: ConfigurationResources = { 3 \u0026#34;Region\u0026#34;: \u0026#34;some-value\u0026#34;, 4 \u0026#34;LeoStream\u0026#34;: \u0026#34;some-value\u0026#34;, 5 \u0026#34;LeoCron\u0026#34;: \u0026#34;some-value\u0026#34;, 6 \u0026#34;LeoSettings\u0026#34;: \u0026#34;some-value\u0026#34;, 7 \u0026#34;LeoEvent\u0026#34;: \u0026#34;some-value\u0026#34;, 8 \u0026#34;LeoKinesisStream\u0026#34; : \u0026#34;some-value\u0026#34;, 9 \u0026#34;LeoFirehoseStream\u0026#34;: \u0026#34;some-value\u0026#34;, 10 \u0026#34;LeoS3\u0026#34;: \u0026#34;some-value\u0026#34; 11}; 12 13const rsdk: RStreamsSdk = new RStreamsSdk(RSTREAMS_BUS_CONFIG); \r Principle Operations Write\nYou\u0026rsquo;re going to want to write to the bus, meaning send a data event to a specific queue of the bus. Queues maintain their order, with the newest at the front of the queue and the oldest data at the back of the queue.\nRead\nYou\u0026rsquo;re going to want to read from the bus, meaning read events from a queue of the bus. You typically read from the last place you read from last in a queue. Or, if this is your bot\u0026rsquo;s first time reading from a queue then the oldest event in the queue is the default. Or, you can read events in a specific range back in time in the queue.\nTransform\nYou\u0026rsquo;re going to want to read from the bus, change the data somehow or cause a side effect like writing to some database, and then write the changed data to a different queue.\nWrite to the bus TODO: include link to git project so can checkout and run\nWrite a single object to the bus Let\u0026rsquo;s say we want to populate an RStreams queue with people we retrieve from an API that generates random people. The steps to do that are\n Line 6 : Create an instance of the SDK Line 7 : Go get a single random person from a public API using the Axios library Line 8 : Call the putEvent SDK API to send an event up to the RStreams Bus  The first argument is the ID of the bot this code is running as The second argument is the ID of the RStreams queue to send the event to The third argument is the JSON object to send    1import { ConfigurationResources, RStreamsSdk } from \u0026#34;leo-sdk\u0026#34;; 2import { PersonRaw, PersonRawResults } from \u0026#34;../lib/types\u0026#34;; 3import axios from \u0026#34;axios\u0026#34;; 4 5async function main() { 6 const rsdk: RStreamsSdk = new RStreamsSdk(); 7 const person = await getRandomPerson(); 8 await rsdk.putEvent(\u0026#39;rstreams-example.load-people\u0026#39;, \u0026#39;rstreams-example.people\u0026#39;, person); 9} 10 11async function getRandomPerson(): Promise\u0026lt;PersonRaw\u0026gt; { 12 const NUM_EVENTS = 1; 13 const url = `https://randomuser.me/api/?results=${NUM_EVENTS}\u0026amp;` + 14 `exc=login,registered,phone,cell,picture,id\u0026amp;noinfo`; 15 const {data, status} = await axios.get\u0026lt;PersonRawResults\u0026gt;(url); 16 17 if (status !== 200) { 18 throw new Error(\u0026#39;Unable to get randomPeople from https://randomuser.me API: \u0026#39; + status); 19 } 20 21 console.log(\u0026#39;Person: \u0026#39; + data.results[0].name.first + \u0026#39; \u0026#39; + data.results[0].name.last); 22 23 return data.results[0]; 24} 25 26(async () =\u0026gt; { 27 await main(); 28})() \r PersonRaw \u0026amp; PersonRawResults interfaces\r 1export interface PersonRaw { 2 gender: string; 3 name: { 4 title: string; 5 first: string; 6 last: string; 7 } 8 location: { 9 street: { 10 number: number; 11 name: string; 12 } 13 city: string; 14 state: string; 15 country: string; 16 postcode: number; 17 coordinates: { 18 longitude: string; 19 latitude: string; 20 } 21 timezone: { 22 offset: string; 23 description: string; 24 } 25 } 26 email: string; 27 dob: { 28 date: string; 29 age: number; 30 } 31 nat: string; 32} 33 34export interface PersonRawResults { 35 results: PersonRaw[]; 36} \r View results in Botmon\nIf you go to Botmon, you will see that the rstreams-example.people queue now has an event in it. Expand for Botmon screenshots  \r  Go to Botmon and search for rstreams-example.people in the search field   Botmon now shows a visual representation of the bot and the queue, click on the gear icon after hovering over the queue and then click on Events   Botmon now shows the events loaded into the queue   \r\nWrite multiple objects to the bus So, instead of reading one person from the public API we used in the example above, let\u0026rsquo;s say we get 100 people at a time from the public API and we want to write them to the bus. Here\u0026rsquo;s what that looks like.\n1import { ConfigurationResources, RStreamsSdk } from \u0026#34;leo-sdk\u0026#34;; 2import { PersonRawResults } from \u0026#34;../lib/types\u0026#34;; 3import axios from \u0026#34;axios\u0026#34;; 4 5async function main() { 6 const rsdk: RStreamsSdk = new RStreamsSdk(); 7 const people = await getRandomPeople(); 8 9 //HINT: this will have very bad performance. This is just to illustrate a point. 10 // Don\u0026#39;t use putEvent in a loop this way in practice! 11 for (const person of people.results) { 12 await rsdk.putEvent(\u0026#39;rstreams-example.load-people\u0026#39;, \u0026#39;rstreams-example.people\u0026#39;, person); 13 } 14} 15 16async function getRandomPeople(): Promise\u0026lt;PersonRawResults\u0026gt; { 17 const NUM_EVENTS = 100; 18 const url = `https://randomuser.me/api/?results=${NUM_EVENTS}\u0026amp;` + 19 `exc=login,registered,phone,cell,picture,id\u0026amp;noinfo`; 20 const {data, status} = await axios.get\u0026lt;PersonRawResults\u0026gt;(url); 21 22 if (status !== 200) { 23 throw new Error(\u0026#39;Unable to get randomPeople from https://randomuser.me API: \u0026#39; + status); 24 } 25 26 console.log(\u0026#39;Person: \u0026#39; + data.results[0].name.first + \u0026#39; \u0026#39; + data.results[0].name.last); 27 28 return data; 29} 30 31(async () =\u0026gt; { 32 await main(); 33})() The only difference in this example is that we pass in 100 to the public API, getting back 100 objects as an array. We then loop through them, making a connection to the RStreams Bus for each and every event. It\u0026rsquo;s simple and it works but this is bad. The putEvent API is really only meant for one or maybe a handful of events. To understand why, consider what the RStreams SDK is doing when you call putEvent.\n It\u0026rsquo;s opening a connection to AWS Kinesis It sending the single event on that connection each time to Kinesis The event flows through Kinesis until an RStreams Kinesis processor reads the single event and writes it to the RStreams Dynamo DB queue table, putting the event in the correct queue  RStreams is designed to handle the continuos generation of data events that flow into a given queue, is read from that queue and mutated and then sent to other queues. It is today doing this with very large amounts of concurrently received events. The RStreams SDK has a better way to work with sending larger amounts of data to the bus, meaning to an RStreams queue.\nStream multiple objects to the bus fast It\u0026rsquo;s time to tackle the idea of streams. If you aren\u0026rsquo;t well versed on streams, jump over and read the Streams Primer. It\u0026rsquo;s short and sweet and may well convert you to streams if you aren\u0026rsquo;t already.\n1import { RStreamsSdk } from \u0026#34;leo-sdk\u0026#34;; 2import { PersonRawResults } from \u0026#34;../lib/types\u0026#34;; 3import axios from \u0026#34;axios\u0026#34;; 4 5async function main() { 6 const rsdk: RStreamsSdk = new RStreamsSdk(); 7 const es = rsdk.streams.eventstream; 8 const people = await getRandomPeople(); 9 10 rsdk.streams.pipeAsync( 11 es.readArray(people.results), 12 rsdk.load(\u0026#39;rstreams-example.load-people\u0026#39;, \u0026#39;rstreams-example.people\u0026#39;, 13 {records: 25, time: 5000, useS3: true}) 14 ); 15} 16 17async function getRandomPeople(): Promise\u0026lt;PersonRawResults\u0026gt; { 18 const NUM_EVENTS = 100; 19 const url = `https://randomuser.me/api/?results=${NUM_EVENTS}\u0026amp;` + 20 `exc=login,registered,phone,cell,picture,id\u0026amp;noinfo`; 21 const {data, status} = await axios.get\u0026lt;PersonRawResults\u0026gt;(url); 22 23 if (status !== 200) { 24 throw new Error(\u0026#39;Unable to get randomPeople from https://randomuser.me API: \u0026#39; + status); 25 } 26 27 return data; 28} 29 30(async () =\u0026gt; { 31 await main(); 32})() "},{"url":"https://rstreams.org/why-rstreams/getting-started/","title":"Getting Started","description":"","content":"RStreams is a server-side bus installed in an AWS account and an SDK for creating reactive applications that use the bus and a monitoring web app called Botmon. RStreams Flow is an opinionated framework to make getting a client-side project up and running super easy.\n"},{"url":"https://rstreams.org/rstreams-node-sdk/streams-primer/","title":"Streams Primer","description":"","content":"\r ToC\r   Readable Writeable Duplex Transform or Through    \r This primer provides exactly enough knowledge of streaming concepts for a developer to successfully write streaming applications using the RStreams SDK and bus. It is not intended as an exhaustive treatise on the vagaries of Node streams. We all have work to do.\n Overview There truly is nothing new under the sun. Streaming is really nothing more than Unix pipes, albeit in a more distributed manner, invented more than 50 years ago. The RStreams Node SDK relies on streaming data in and out just exactly as Unix pipes stream together commands in POSIX-based systems.\nStreaming involves creating a series of steps in a pipe where the first step, the Source, generates the data to move through the pipe. The last step is the Sink, whose job it is to do something with the data moving through the pipe. The Sink is responsible for pulling data from the previous step, which causes data to flow in the pipe: no Sink step in the pipe means no data flows. In between the source step and the sink step may optionally be any number of Transform steps that can modify data that flows through the pipe on its way to the sink.\n  Care to hear why some think streams are too hard?\r Streams get a bad rap. There are some who claim learning to stream data is too hard for developers. Most who dis on streams were quoted some years ago, though you can still find some articles today. The negativity was a reaction to Java and Node and C# releasing streams and their functional programming approach, which was uber complex and often used when it shouldn\u0026rsquo;t have been.\nThis is in large measure because streams became synonymous with functional programming in Java and C# and elsewhere. Java’s streaming solution, which is how many got their first experience with streaming, is complicated, ill suited to streaming because of Java’s verbosity and feel to many developers like regular expressions: going back to one requires painstakingly decomposing what it is doing, having to understand code that is hard to read and understand.\nNode’s original streaming API was hard to understand and use and has been significantly improved over the years. Don\u0026rsquo;t worry, the RStreams Node SDK dramatically simplifies it for you. \r  Care to read why streams might be worth it for you?\r Why code in a series of chained steps? Sounds complicated. The answer is you turn to streaming when you are working with systems where you need to process data as it is coming in because so much data needs to flow in that you can\u0026rsquo;t wait to start sending it out.\nIt\u0026rsquo;s also applicable when you need to minimize the delay in processing lots of data. Finally, it\u0026rsquo;s a great way to creat a reactive system, where the data that flows are events that cause distributed event handlers to wake up and process them, moving and transforming them from one place to another.\n\r Pipes and Streams As mentioned, a pipe is a set of steps that data flows through in sequence. Each step in the pipe is itself called a stream because they are meant to read/write data sequentially one after the other. Steps near the beginning of the pipe are upstream and the Sink downstream: data flows is the furthest step downstream. The pipe exists to daisy chain the stream steps together.\nReadable In node, a pipe is a function and each argument is a step, thus a stream, in the pipe. The first step, the Source, must get or create data somehow. It might do this by continuosly querying a database and making the data available for the next step to grab it. Remember that each downstream step pulls data from the step before it. In other words, the Source step must be readable by the next step so it can pull data from it. So, Source steps will always be of the Node type Readable. For example, the fs.createReadStream() Node file function will create a source stream that reads data from a file.\nA Readable stream is an abstraction for a source from which data can be consumed.\nThe RStreams SDK provides extremely simple Readable interfaces to make getting data from an RStreams bus queue a breeze. These simplified RStreams SDK pipe steps are of the RStreams SDK type ReadableStream which inherits from the Node Readable.\nWriteable The last step in a pipe, the Sink, needs to be able to do something with the data. In other words, it needs to be a step we can write to such as fs.createWriteStream() that creates a Sink stream that will write the data flowing through the pipe to a file.\nA Writable stream is an abstraction for a destination to which data can be written.\nThe RStreams SDK provides extremely simple Writable interfaces to make sending data to other resources, such as a database or Elastic Search, etc., a snap. These simplified RStreams SDK pipe steps are of the RStreams SDK type WritableStream which inherits from the Node Writable. That\u0026rsquo;s all you need to know.\nDuplex A stream step that sits between the Source and the Sink is by definition a Duplex stream. Think of a Duplex stream like its really two streams smashed together. The input to the Duplex stream is a Writable so it can consume the data from the Readable in the step before it. The output from the Duplex stream is a Readable so the next step downstream can pull data from it.\nA Duplex stream is one that is both Readable and Writeable at the same time, e.g. a TCP socket.\n Transform or Through A Transform stream is just a Duplex stream with a function that modifies the data or perhaps causes some other side effect and then sends the data downstream. A Transform stream is often called a Through stream.\nA Transform stream is a duplex stream that allows you to transform the data in between when it is written to the stream and later read from the stream.\nThe RStreams SDK provides extremely simple Transform interfaces to make moving data through a pipe easy. These simplified RStreams SDK pipe steps are of the RStreams SDK type TransformStream which inherits from the Node Duplex.\n "},{"url":"https://rstreams.org/rstreams-guides/core-concepts/event-streaming-primer/","title":"Event Streaming Primer","description":"In-depth guides and how-to&#39;s.","content":"One cannot understand the problems RStreams solves or reason about its implementation/usage without a fundamental understanding of event streaming compared to traditional microservices approaches.\nSummary Some systems work with parties that are constantly generating new data. Client data flowing from these parties tends to flow in a sequential order that we call an event stream. The events in this stream get transformed, enriched, and used to trigger subsequent events. Event stream processing, in concert with general purpose messaging, is a loosely coupled, scalable pattern ideal for designing enterprise systems built to handle continuous data flow. RStreams is just such a system.\n"},{"url":"https://rstreams.org/rstreams-flow/","title":"RStreams Flow","description":"Be up and running in 10 minutes.","content":"RStreams Flow is an opinionated framework that makes choices on how to build, test, deploy, monitor and maintain RStreams microservices. Engineers don’t care about RStreams. They care about creating reactive microservices that leverage native AWS services at scale. RStreams Flow helps engineers just do their work.\n"},{"url":"https://rstreams.org/rstreams-flow/configuring-rstreams/","title":"Configuring RStreams","description":"","content":"TODO\n"},{"url":"https://rstreams.org/rstreams-guides/","title":"RStreams Guides","description":"In-depth guides and how-to&#39;s.","content":"This section includes guides that cover RStreams core concepts and common use cases.\n"},{"url":"https://rstreams.org/rstreams-node-sdk/","title":"RStreams Node SDK","description":"The smart SDK for Node/Typescript.","content":"This is the RStreams Node SDK, a client-side library designed to interact with instances of an RStreams Bus.\nThis assumes you\u0026rsquo;ve got an RStreams Bus instance running to connect to. If you don\u0026rsquo;t, head on over to the RStreams Bus section first. \nAlso, the RStreams Bus gets your Node/Typescript project setup in a jiffy with the right SDK config, ready to run local, debug and deploy if you haven\u0026rsquo;t already done that.\n Are you setup to run the examples? Expand this section if you\u0026rsquo;re not sure  \rAll examples in the SDK documentation assume that when these apps run, the RStreams SDK can discover the configuration it needs. The config it needs is the AWS resource IDs of the RStreams Bus instance deployed in your AWS account. Things like the ID of the kinesis stream used by the bus and so on.\nOf course, in a production environment the SDK will get the config in an intelligent and safe manner, say from AWS Secrets Manager. See the RStreams Flow Configuring RStreams doc.\nHere\u0026rsquo;s the typescript type of the config.\nGet the config You will first need to get this config. By default, the RStreams Bus puts a secret in secrets manager that is the JSON config blob. The secret will be named rstreams-\u0026lt;bus name\u0026gt;. Go get the JSON config from this secret.\nSave the config As a file Create a file named rstreams.config.json and put it in the same directory you are running your app in or in any parent director and the SDK will just find it and use it.\nAs an environment variable Create an environment variable named RSTREAMS_CONFIG whose value is the config JSON blob.\nAs an argument to the SDK itself Create a variable in the code that is the config and then pass it into the SDK\u0026rsquo;s constructor.\n1 2const RSTREAMS_BUS_CONFIG: ConfigurationResources = { 3 \u0026#34;Region\u0026#34;: \u0026#34;some-value\u0026#34;, 4 \u0026#34;LeoStream\u0026#34;: \u0026#34;some-value\u0026#34;, 5 \u0026#34;LeoCron\u0026#34;: \u0026#34;some-value\u0026#34;, 6 \u0026#34;LeoSettings\u0026#34;: \u0026#34;some-value\u0026#34;, 7 \u0026#34;LeoEvent\u0026#34;: \u0026#34;some-value\u0026#34;, 8 \u0026#34;LeoKinesisStream\u0026#34; : \u0026#34;some-value\u0026#34;, 9 \u0026#34;LeoFirehoseStream\u0026#34;: \u0026#34;some-value\u0026#34;, 10 \u0026#34;LeoS3\u0026#34;: \u0026#34;some-value\u0026#34; 11}; 12 13const rsdk: RStreamsSdk = new RStreamsSdk(RSTREAMS_BUS_CONFIG); \r Do you know how to access Botmon? Expand this section if you\u0026rsquo;re not sure  \rBotmon is a visualization, monitoring and debugging tool that installs with an instance of the RStreams as a website. Most examples will have you use Botmon to visualize what\u0026rsquo;s happening and to help diagnose issues.\nTODO: how do they know how to access botmon?\n\r "},{"url":"https://rstreams.org/rstreams-bus/","title":"RStreams Bus","description":"RStreams event bus, built with native AWS services.","content":"The RStreams Bus is a light-weight framework that uses AWS Kinesis, S3, Lambda and Dynamo DB to create an event-streaming and general purpose messaging platform.\n"},{"url":"https://rstreams.org/rstreams-botmon/","title":"RStreams Monitoring","description":"Monitor, trace and debug events in the bus in real-time.","content":"RStreams includes a webapp called Botmon that provides real time monitoring, data visualization, tracing and debugging.\n"},{"url":"https://rstreams.org/rstreams-guides/core-concepts/","title":"Core Concepts","description":"In-depth guides and how-to&#39;s.","content":"Start here to get an understanding of core concepts that govern the RStreams platform. The Event Streaming Primer is a realy good place to start.\n"},{"url":"https://rstreams.org/","title":"RStreams","description":"","content":""},{"url":"https://rstreams.org/categories/","title":"Categories","description":"","content":""},{"url":"https://rstreams.org/changelog/","title":"Changelog posts","description":"Lorem ipsum dolor sit amet, consetetur sadipscing elitr, sed diam nonumy eirmod tempor invidunt dolore magna aliquyam erat, sed diam voluptua. At vero eos et ustoLorem ipsum dolor sit amet, consetetur.","content":"February Updates Feb 6, 2019\nLorem ipsum dolor sit amet, consetetur sadipscing elitr, sed diam nonumy eirmod tempor invidunt dolore magna aliquyam erat, sed diam voluptua. At vero eos et ustoLorem ipsum dolor sit amet, consetetur.\u0026quot;\nChanged\r  Better support for using applying additional filters to posts_tax_query for categories for custom WordPress syncs\n  Reporting fine-tuning for speed improvements (up to 60% improvement in latency)\n  Replaced login / registration pre-app screens with a cleaner design\n   Removed\r Removed an issue with the sync autolinker only interlinking selectively. Removed up an issue with prematurely logging out users   \rMarch Updates Mar 6, 2019\nLorem ipsum dolor sit amet, consetetur sadipscing elitr, sed diam nonumy eirmod tempor invidunt dolore magna aliquyam erat, sed diam voluptua. At vero eos et ustoLorem ipsum dolor sit amet, consetetur.\u0026quot;\nAdded\r Some scheduled changelogs, tweets, and slack messages queued up this weekend and were not published on time. We fixed the issue and all delayed publications should be out. We now prioritize keywords over title and body so customers can more effectively influence search results Support form in the Assistant is now protected with reCaptcha to reduce spam reinitializeOnUrlChange added to the JavaScript API to improve support for pages with turbolinks   Fixed\r Fixed an issue with the sync autolinker only interlinking selectively. Fixed up an issue with prematurely logging out users   \rChangelog label Added\r Changed\r Depricated\r Removed\r Fixed\r Security\r Unreleased\r "},{"url":"https://rstreams.org/contact/","title":"Got Any Questions","description":"this is meta description","content":""},{"url":"https://rstreams.org/rstreams-node-sdk/api-docs/","title":"SDK API Docs","description":"The generated RStreams Node SDK API Docs","content":"Jump over to the RStreams Node SDK API Docs.\n"},{"url":"https://rstreams.org/search/","title":"Search Result","description":"this is meta description","content":""},{"url":"https://rstreams.org/tags/","title":"Tags","description":"","content":""}]